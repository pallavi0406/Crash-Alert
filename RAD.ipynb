{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install twilio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZsmuiejYFsv",
        "outputId": "63d85c91-e71f-4466-9a50-bda9733eb921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting twilio\n",
            "  Downloading twilio-9.4.6-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from twilio) (2.32.3)\n",
            "Requirement already satisfied: PyJWT<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from twilio) (2.10.1)\n",
            "Requirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.11/dist-packages (from twilio) (3.11.13)\n",
            "Collecting aiohttp-retry>=2.8.3 (from twilio)\n",
            "  Downloading aiohttp_retry-2.9.1-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->twilio) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->twilio) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->twilio) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->twilio) (2025.1.31)\n",
            "Downloading twilio-9.4.6-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_retry-2.9.1-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: aiohttp-retry, twilio\n",
            "Successfully installed aiohttp-retry-2.9.1 twilio-9.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image as PILImage\n",
        "from IPython.display import display, Javascript, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import wave\n",
        "import time\n",
        "from twilio.rest import Client"
      ],
      "metadata": {
        "id": "ElE9g-z-ZqgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries if not already installed\n",
        "!pip install opencv-python-headless twilio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxnjTKGOZwu7",
        "outputId": "8f6b5e5b-71b6-4967-8c6d-e0a18a12897d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: twilio in /usr/local/lib/python3.11/dist-packages (9.4.6)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from twilio) (2.32.3)\n",
            "Requirement already satisfied: PyJWT<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from twilio) (2.10.1)\n",
            "Requirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.11/dist-packages (from twilio) (3.11.13)\n",
            "Requirement already satisfied: aiohttp-retry>=2.8.3 in /usr/local/lib/python3.11/dist-packages (from twilio) (2.9.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->twilio) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->twilio) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->twilio) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->twilio) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download YOLOv4 configuration and weights\n",
        "!wget https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4.cfg -O yolov4.cfg\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/yolov4/yolov4.weights -O yolov4.weights\n",
        "!wget https://raw.githubusercontent.com/AlexeyAB/darknet/master/data/coco.names -O coco.names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjXmOYB2Z3_4",
        "outputId": "264ba4bd-8423-4e28-e796-ed3bf82e46f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-01 03:22:48--  https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4.cfg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12231 (12K) [text/plain]\n",
            "Saving to: ‘yolov4.cfg’\n",
            "\n",
            "\ryolov4.cfg            0%[                    ]       0  --.-KB/s               \ryolov4.cfg          100%[===================>]  11.94K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-01 03:22:48 (24.1 MB/s) - ‘yolov4.cfg’ saved [12231/12231]\n",
            "\n",
            "--2025-03-01 03:22:48--  https://github.com/AlexeyAB/darknet/releases/download/yolov4/yolov4.weights\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/75388965/749e43d0-8605-436f-b26c-12ee01c2a265?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250301%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250301T032248Z&X-Amz-Expires=300&X-Amz-Signature=fe84efff4635ccfd27ac2e25da49c276487addc4fc5b15861ba5763e39d6a5c9&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov4.weights&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-03-01 03:22:48--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/75388965/749e43d0-8605-436f-b26c-12ee01c2a265?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250301%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250301T032248Z&X-Amz-Expires=300&X-Amz-Signature=fe84efff4635ccfd27ac2e25da49c276487addc4fc5b15861ba5763e39d6a5c9&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov4.weights&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257717640 (246M) [application/octet-stream]\n",
            "Saving to: ‘yolov4.weights’\n",
            "\n",
            "yolov4.weights      100%[===================>] 245.78M   126MB/s    in 2.0s    \n",
            "\n",
            "2025-03-01 03:22:50 (126 MB/s) - ‘yolov4.weights’ saved [257717640/257717640]\n",
            "\n",
            "--2025-03-01 03:22:50--  https://raw.githubusercontent.com/AlexeyAB/darknet/master/data/coco.names\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 625 [text/plain]\n",
            "Saving to: ‘coco.names’\n",
            "\n",
            "coco.names          100%[===================>]     625  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-01 03:22:50 (48.1 MB/s) - ‘coco.names’ saved [625/625]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv4 model\n",
        "net = cv2.dnn.readNet(\"yolov4.weights\", \"yolov4.cfg\")\n",
        "\n",
        "# Load COCO class names\n",
        "with open(\"coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# Define vehicle and person classes\n",
        "vehicle_classes = {\"car\", \"bus\", \"truck\", \"motorcycle\"}\n",
        "person_classes = {\"person\"}\n",
        "target_classes = vehicle_classes | person_classes  # Union of vehicle and person classes\n",
        "\n",
        "# Get the output layer names\n",
        "layer_names = net.getLayerNames()\n",
        "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers().flatten()]\n",
        "\n",
        "# Function to capture an image from webcam (only works in Colab)\n",
        "def capture_image(filename='photo.jpg', quality=0.8):\n",
        "    js = Javascript('''\n",
        "        async function captureImage(quality) {\n",
        "            const video = document.createElement('video');\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            document.body.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            // Wait for the video to load\n",
        "            await new Promise(resolve => setTimeout(resolve, 1000));\n",
        "\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "            const dataUrl = canvas.toDataURL('image/jpeg', quality);\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            video.remove();\n",
        "            canvas.remove();\n",
        "\n",
        "            return dataUrl;\n",
        "        }\n",
        "    ''')\n",
        "\n",
        "    display(js)\n",
        "    data_url = eval_js('captureImage({})'.format(quality))\n",
        "    binary = b64decode(data_url.split(',')[1])\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "    return filename\n",
        "\n",
        "# Function to detect objects (vehicles and persons) in the image\n",
        "def detect_objects(image):\n",
        "    height, width, channels = image.shape\n",
        "\n",
        "    # Prepare the image for the neural network\n",
        "    blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    outs = net.forward(output_layers)\n",
        "\n",
        "    # Initialization\n",
        "    class_ids, confidences, boxes = [], [], []\n",
        "\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "\n",
        "            # Ensure the class_id is valid and check if it's a vehicle or person\n",
        "            if confidence > 0.5 and 0 <= class_id < len(classes) and classes[class_id] in target_classes:\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "\n",
        "    # Draw bounding boxes and labels\n",
        "    for i in range(len(boxes)):\n",
        "        if i in indexes:\n",
        "            x, y, w, h = boxes[i]\n",
        "            label = str(classes[class_ids[i]])\n",
        "            confidence = confidences[i]\n",
        "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            cv2.putText(image, f\"{label}: {confidence:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    return image, boxes, class_ids\n",
        "\n",
        "# Function to detect potential accidents based on proximity\n",
        "def detect_accidents(boxes, class_ids):\n",
        "    accident_detected = False\n",
        "    for i in range(len(boxes)):\n",
        "        for j in range(i + 1, len(boxes)):\n",
        "            box1 = boxes[i]\n",
        "            box2 = boxes[j]\n",
        "            label1 = classes[class_ids[i]]\n",
        "            label2 = classes[class_ids[j]]\n",
        "\n",
        "            # Check if one of them is a vehicle and the other is a person\n",
        "            if (label1 in vehicle_classes and label2 in person_classes) or (label1 in person_classes and label2 in vehicle_classes):\n",
        "                # Check for overlap or close proximity\n",
        "                if (box1[0] < box2[0] + box2[2] and box1[0] + box1[2] > box2[0] and\n",
        "                    box1[1] < box2[1] + box2[3] and box1[1] + box1[3] > box2[1]):\n",
        "                    print(f\"ALERT: Potential accident detected \")\n",
        "                    accident_detected = True\n",
        "                    break\n",
        "        if accident_detected:\n",
        "            break\n",
        "    if not accident_detected:\n",
        "      print(\"No accident detected\")\n",
        "    return accident_detected\n",
        "\n",
        "# Function to create and play an alarm sound\n",
        "def play_alarm():\n",
        "    # Parameters for the sine wave\n",
        "    frequency = 3000  # Hz\n",
        "    fs = 44100  # Sampling rate\n",
        "    duration = 2  # Duration in seconds\n",
        "\n",
        "    # Generate time points\n",
        "    t = np.linspace(0, duration, int(fs * duration), endpoint=False)\n",
        "\n",
        "    # Generate a sine wave at the desired frequency\n",
        "    note = np.sin(4 * np.pi * frequency * t)\n",
        "\n",
        "    # Normalize to 16-bit range\n",
        "    audio = np.int16(note / np.max(np.abs(note)) * 32767)\n",
        "\n",
        "    # Save the sine wave as a WAV file\n",
        "    with wave.open('alarm.wav', 'w') as wf:\n",
        "        wf.setnchannels(1)  # mono\n",
        "        wf.setsampwidth(2)  # 16-bit\n",
        "        wf.setframerate(fs)\n",
        "        wf.writeframes(audio.tobytes())\n",
        "\n",
        "    # Play the audio\n",
        "    display(Audio('alarm.wav', autoplay=True))\n",
        "# Function to make a phone call\n",
        "'''def make_phone_call():\n",
        "    # Twilio credentials (replace with your actual credentials)\n",
        "    account_sid = 'ACa31c7c9da1fdf22a02669a5bc2e8c875'  # Replace with your Account SID\n",
        "    auth_token = 'a40e1168e32f6c9aaea3655e14169c1d'  # Replace with your Auth Token\n",
        "    client = Client(account_sid, auth_token)\n",
        "\n",
        "    # Your Twilio phone number\n",
        "    twilio_number = '+17623830847'  # Replace with your Twilio phone number\n",
        "\n",
        "    # The number to call (replace with the actual phone number)\n",
        "    to_number = '+917901463339'  # Replace with the recipient's phone number\n",
        "\n",
        "    call = client.calls.create(\n",
        "        twiml='<Response><Say>An accident has been detected. Please respond accordingly.</Say></Response>',\n",
        "        to=to_number,\n",
        "        from_=twilio_number\n",
        "    )\n",
        "\n",
        "    print(f\"Call initiated, SID: {call.sid}\")'''\n",
        "\n",
        "# Function to display and process live feed automatically\n",
        "def live_feed():\n",
        "    try:\n",
        "        while True:\n",
        "            # Capture an image\n",
        "            filename = capture_image()\n",
        "            print(f\"Captured Image: {filename}\")\n",
        "\n",
        "            # Load the captured image\n",
        "            image = cv2.imread(filename)\n",
        "\n",
        "            if image is None:\n",
        "                print(\"Error: Image not loaded correctly.\")\n",
        "                continue\n",
        "\n",
        "            # Detect vehicles and persons in the captured image\n",
        "            result_image, boxes, class_ids = detect_objects(image)\n",
        "\n",
        "            # Detect potential accidents\n",
        "            accident_detected = detect_accidents(boxes, class_ids)\n",
        "\n",
        "            # Display the output image\n",
        "            result_pil_image = PILImage.fromarray(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))\n",
        "            display(result_pil_image)\n",
        "\n",
        "            # Play alarm sound and make phone call if an accident is detected\n",
        "            if accident_detected:\n",
        "                play_alarm()\n",
        "                '''make_phone_call()'''\n",
        "            else:\n",
        "                print(\"No accident detected\")\n",
        "\n",
        "            time.sleep(2)  # Add a delay to control the frame rate\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Live feed stopped by user.\")\n",
        "\n",
        "# Start live feed\n",
        "live_feed()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "HK3kwDbZnzK2",
        "outputId": "acca2be0-ff9e-4338-8e83-26d316093100"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function captureImage(quality) {\n",
              "            const video = document.createElement('video');\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "            document.body.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            // Wait for the video to load\n",
              "            await new Promise(resolve => setTimeout(resolve, 1000));\n",
              "\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "\n",
              "            const dataUrl = canvas.toDataURL('image/jpeg', quality);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            video.remove();\n",
              "            canvas.remove();\n",
              "\n",
              "            return dataUrl;\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Captured Image: photo.jpg\n",
            "Live feed stopped by user.\n"
          ]
        }
      ]
    }
  ]
}
